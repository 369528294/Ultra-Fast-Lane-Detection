# 机器人车道居中导航算法说明

本文档描述基于视觉车道线检测的**车道居中导航**算法：从摄像头/视频输入到横向偏差计算、PID 转向修正量输出的完整流程，便于在机器人上实现“沿当前车道中心线行驶”的横向控制。

---

## 1. 概述

### 1.1 目标

- 实时检测当前车道的左右边界（车道线）。
- 计算**当前车道中心线**（非整条道路中心）。
- 用**最靠近机器人**的一点（画面最底部中心点）计算横向偏差。
- 通过 **PID** 输出平滑的**转向修正量 steer**，供机器人执行“向左/向右/居中”的横向控制。

### 1.2 整体流程

```
摄像头/视频 → 车道线检测(CNN) → 左右车道线(绿点)
                    ↓
            当前车道中心线(红线) + 最底部中心点(大红点)
                    ↓
            原始横向偏差 raw_error = 底部中心点x - 画面中心x
                    ↓
            滤波：filtered_error = 0.8*prev_error + 0.2*raw_error（防抖）
                    ↓
            低频控制(10Hz)：PID(filtered_error, dt) → steer
                    ↓
            限幅：steer = clamp(steer, -1, 1)（防暴走）
                    ↓
            机器人控制接口(舵机/差速等)
```

---

## 2. 车道线检测

- **模型**：Ultra-Fast-Lane-Detection（Tusimple 预训练，ResNet-18 backbone）。
- **输入**：单帧图像，预处理为 288×800，ImageNet 归一化。
- **输出**：每条车道在 56 个行锚上的横向位置（网格分类解码为亚像素横坐标），最多 4 条车道。
- **可视化**：检测到的车道线在画面上用**绿色点**标出。

行锚顺序：`center[0]` 对应**画面最下方**（最接近车），`center[-1]` 对应**画面最上方**（远处）。

---

## 3. 当前车道中心线

### 3.1 为何是“当前车道”

- 多车道时，需要的是**本车所在车道**的中心，而不是整条路的几何中心。
- 假设车头大致对准画面中心，用**画面中心**作为参考，选出“夹住”画面中心的两条车道线。

### 3.2 算法步骤

1. 对每条检测到的车道，用有效点的横坐标求**平均 x**。
2. **左边界**：在 `avg_x < 画面中心x` 的车道中，取 `avg_x` **最大**的一条（最靠右的左线）。
3. **右边界**：在 `avg_x ≥ 画面中心x` 的车道中，取 `avg_x` **最小**的一条（最靠左的右线）。
4. 对左右两条线**按行对齐**，在每一行取左右点的中点，得到当前车道**中心线**点列 `center`。
5. 仅当左右都有效（`l[0]>0 and r[0]>0`）时才加入中心点，避免缺一侧时中心线偏到一边。

### 3.3 可视化

- **红线**：当前车道中心线（相邻点连线段）。
- **大红点**：中心线**最底部一点**（`center[0]`），即最接近机器人的参考点，用于后续偏差与 PID。

---

## 4. 横向偏差与视觉参考线

### 4.1 横向偏差 error

- **参考点**：中心线最底部一点 `center[0]` 的横坐标 `cx`。
- **参考基准**：画面正中央横坐标 `camera_center = img_width / 2`（视觉/相机中心）。
- **定义**：
  ```text
  error = cx - camera_center
  ```
- **含义**：
  - **error > 0**：底部中心点在画面中心右侧 → 车相对车道**偏左** → 需**向右**纠偏。
  - **error < 0**：底部中心点在画面中心左侧 → 车相对车道**偏右** → 需**向左**纠偏。
  - **error = 0**：底部中心点与画面中心重合 → **居中**。

无有效中心线时（`center is None` 或空），可令 `error = 0` 或不做控制。

### 4.2 蓝色参考线

- 在画面正中央画一条**蓝色竖线**：`x = img_width / 2`。
- 用于与**红线/红点**对比，直观看出偏左/偏右及偏差大小。

---

## 5. PID 与转向修正量 steer

### 5.1 为何用 PID

- 直接用 `error` 控制容易抖动、超调。
- PID 对 error 做比例、积分、微分组合，得到**平滑的转向修正量**，使机器人运动更平滑、稳定。

### 5.2 标准 PID 形式

```text
u(t) = Kp·e(t) + Ki·∫e(τ)dτ + Kd·de(t)/dt
```

- `e(t)`：当前横向偏差 `error`（像素）。
- `dt`：与上一帧的时间间隔（秒）。
- 离散实现：积分用累加 `sum += error * dt`，微分用 `(error - prev) / dt`。

### 5.3 steer 的含义

- **steer** = PID 的输出，即**转向修正量**（控制量）。
  - **steer > 0**：需要**向右转**（例如车偏左时把车拉回车道中心）。
  - **steer < 0**：需要**向左转**。
  - **steer = 0**：无需转向。
- **幅度**：绝对值越大，转向越强；具体映射由机器人执行机构决定。

### 5.4 控制接口示例（轮式/车式）

- **舵机/转向角**：`转向角 = 中值 + K * steer`（K 为缩放系数）。
- **差速/阿克曼**：左轮速 = 基础速度 - K·steer，右轮速 = 基础速度 + K·steer（或按你的车模公式换算）。

将 `steer` 接到上述任一接口即可实现“车道居中”的横向控制。

### 5.5 双足机器人控制思路

双足机器人没有真正的“转向轮”，不能像车一样直接打方向盘，而是通过**步态偏置**或**行走中的轻微旋转**来纠偏。

- **error > 0**：车相对车道偏左 → 需要整体**向右偏**回中心 → 可理解为“需要向右转一点”。
- **error < 0**：车相对车道偏右 → 需要整体**向左偏**回中心。

两种常见做法：

**方式一：步态偏置控制**

- 用 `steer` 调节左右腿步幅，使行走轨迹向一侧偏移。
  - 例如：`error > 0` → 需要向右偏 → **增大左腿步幅、减小右腿步幅**。
- **控制映射**：
  ```text
  left_step  = base + steer
  right_step = base - steer
  ```
  - `base` 为标称步幅；`steer > 0` 时左步大、右步小，整体向右偏。

**方式二：行走中的偏航角速度**

- 在步态周期中给机身一个**偏航角速度**，类似人走路时微调方向。
- **控制映射**：
  ```text
  yaw_rate = steer
  ```
  - 将 `steer` 作为偏航角速度指令，在规划或底层控制中让机器人在行走周期内轻微旋转身体，实现轨迹纠偏。

实际可任选其一或组合使用，再根据机器人步态与动力学做系数缩放和限幅。

### 5.6 默认参数与调参

- 默认：`Kp=0.01, Ki=0, Kd=0.002`。
- **Kp**：比例项，越大响应越快，过大易振荡。
- **Ki**：积分项，消除稳态偏差，一般从小开始加，避免积分饱和。
- **Kd**：微分项，抑制 overshoot，使转向更平滑。

可根据实车/双足机器人响应、帧率与延迟微调。

---

## 6. 实际工程关键点（非常重要）

以下三点必须做，否则容易出现**机器人摇摆、暴走或控制过于敏感**等问题。

### 6.1 必须做滤波

车道检测会抖，若直接把每帧的 `error` 送给 PID，机器人会左右摇摆。

- **做法**：对横向偏差做一阶低通滤波（指数滑动平均）：
  ```text
  filtered_error = 0.8 * prev_error + 0.2 * raw_error
  prev_error = filtered_error
  ```
- **效果**：显示与 PID 输入均使用 `filtered_error`，抑制单帧噪声，运动更平滑。

### 6.2 限幅

防止 PID 输出过大导致机器人暴走。

- **做法**：
  ```text
  steer = max(min(steer, 1.0), -1.0)
  ```
- **说明**：将转向修正量限制在 `[-1, 1]`，再根据执行机构缩放（如舵机角度范围、差速系数）。

### 6.3 低频控制

视觉可以 30 FPS 跑，但**控制不需要每帧都发**，10 Hz 足够且更稳定。

- **做法**：控制周期 0.1 s（10 Hz），仅在该周期到达时执行：
  - `steer = pid.update(filtered_error, dt_control)`
  - `steer = clamp(steer, -1, 1)`
  - 将本次 `steer` 下发到机器人（或用于显示）
- **效果**：避免因帧率波动导致控制频率不均，减少不必要的频繁转向。

---

## 7. 运行与使用

### 7.1 依赖

- 见项目根目录 `requirements.txt` 及 `INSTALL.md`。
- 车道线检测依赖 PyTorch、OpenCV、PIL 等；PID 仅用标准库与 NumPy。

### 7.2 启动方式

```bash
# 视频测试（默认前 10 秒）
python demo_camera.py --source test.mp4

# 视频只播前 5 秒
python demo_camera.py --source test.mp4 --seconds 5

# 摄像头实时
python demo_camera.py

# 使用 CPU（无 GPU 时）
python demo_camera.py --source test.mp4 --no_cuda
```

### 7.3 画面含义

| 元素 | 含义 |
|------|------|
| 绿点 | 检测到的车道线 |
| 红线 | 当前车道中心线 |
| 大红点 | 最底部中心点（用于 error 与 steer） |
| 蓝线 | 画面正中央（视觉中心参考） |
| 左下角文字 | 偏左/居中/偏右 + **滤波后** error；第二行为 `steer: 数值 (10Hz)`（限幅后的 10Hz 控制量） |

---

## 8. 小结

- **车道线检测**：CNN 输出多车道在行锚上的横向位置，转为绿点与车道点列。
- **当前车道中心线**：用画面中心两侧最近的两条线求中线，得到红线和最底部红点。
- **横向偏差**：`raw_error = 底部中心点x - 画面中心x`；经**滤波**得 `filtered_error` 再参与控制；蓝线为视觉中心参考。
- **工程三要素**：**滤波**（0.8*prev+0.2*new）防抖、**限幅**（steer ∈ [-1,1]）防暴走、**10Hz 低频控制**不每帧下发。
- **steer**：PID 在 10Hz 下输出并限幅后的**转向修正量**，接到舵机/差速等即可实现车道居中导航。

上述逻辑均在 `demo_camera.py` 中实现，可直接在该脚本中调整 PID 参数、滤波系数、控制频率或接入实际机器人控制接口。
